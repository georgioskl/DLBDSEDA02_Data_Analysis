{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "367e064f-4c02-4663-808c-3069aa1d4bab",
   "metadata": {},
   "source": [
    "### Die wichtigen Packages importieren und der CSV-Datei einfüngen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "516a696c-0768-4ff0-85fa-de84fdf1a22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\georg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "\n",
    "df = pd.read_csv('consumer_complaints.csv', skipfooter= 551757, engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7376aaa7-4c19-4f38-88b4-9c9e9770e5fc",
   "metadata": {},
   "source": [
    "### Die 'issue' Spalte analysieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10bb6eb7-1eb0-464e-88ba-cf90faaf975f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Loan modification,collection,foreclosure\n",
      "1       Loan servicing, payments, escrow account\n",
      "2         Incorrect information on credit report\n",
      "3                             Repaying your loan\n",
      "4             False statements or representation\n",
      "                          ...                   \n",
      "4195             Disclosure verification of debt\n",
      "4196       Identity theft / Fraud / Embezzlement\n",
      "4197    Loan modification,collection,foreclosure\n",
      "4198             Disclosure verification of debt\n",
      "4199                                       Other\n",
      "Name: issue, Length: 4200, dtype: object\n"
     ]
    }
   ],
   "source": [
    "complaints = df['issue']\n",
    "print(complaints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2073c335-d0d2-48f5-bdce-bee4c2c13946",
   "metadata": {},
   "source": [
    "### Da werden die Kategorien von Spalte 'issue' angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5122e88-51b2-4979-89e9-8a635a0af395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loan modification,collection,foreclosure    808\n",
       "Loan servicing, payments, escrow account    488\n",
       "Incorrect information on credit report      377\n",
       "Cont'd attempts collect debt not owed       327\n",
       "Account opening, closing, or management     218\n",
       "                                           ... \n",
       "Wrong amount charged or received              2\n",
       "Charged fees or interest I didn't expect      2\n",
       "Convenience checks                            1\n",
       "Cash advance                                  1\n",
       "Cash advance fee                              1\n",
       "Name: issue, Length: 64, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['issue'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6baa3e-fe91-44e9-a8d3-c7ba8644ffbb",
   "metadata": {},
   "source": [
    "### Bereinigung des Beschwerdetextes\n",
    "\n",
    "#### Schritt 1: Kleinbuchstabenumwandlung\n",
    "#### Schritt 2: Tokenisierung\n",
    "#### Schritt 3: Entfernung von Stoppwörtern\n",
    "#### Schritt 4: Stemming\n",
    "#### Schritt 5: Lemmatisierung "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51d6d0b3-f6a6-4a45-8180-a5a220cf3e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['issue'] = df['issue'].str.lower()\n",
    "\n",
    "df['issue'] = df['issue'].apply(word_tokenize)\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "df['issue'] = df['issue'].apply(lambda text: [token for token in text if token not in stop_words])\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "df['issue'] = df['issue'].apply(lambda tokens: [stemmer.stem(token) for token in tokens])\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "df['issue'] = df['issue'].apply(lambda tokens: [lemma.lemmatize(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed6bad9-637e-4789-9867-dbb9bacc02a3",
   "metadata": {},
   "source": [
    "### Die Beschwerden sind so strukturiert, dass sie dazu dienen, den Wortschatz zu erweitern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40955be8-9340-4a17-a5d5-90422ef8f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints = []\n",
    "for row in df['issue']:\n",
    "    complaints.append(row)\n",
    "\n",
    "results = [' '.join(ele) for ele in df['issue']]\n",
    "complaints = ' '.join(results)\n",
    "complaints = word_tokenize(complaints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb0372f-0943-4290-98b5-a72e3acbeac1",
   "metadata": {},
   "source": [
    "### Der Wortschatz wurde aufgebaut, wobei jedes einzelne bereinigte Wort aus den Beschwerden nur einmal im Vokabular erscheint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91e227bc-7bc1-4d75-92ad-d204b281186e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loan', 'modif', ',', 'collect', 'foreclosur', 'servic', 'payment', 'escrow', 'account', 'incorrect', 'inform', 'credit', 'report', 'repay', 'fals', 'statement', 'represent', 'applic', 'process', 'delay', 'line', 'increase/decreas', 'deposit', 'withdraw', 'cont', \"'d\", 'attempt', 'debt', 'owe', 'decis', '/', 'underwrit', 'origin', 'mortgag', 'broker', 'communic', 'tactic', 'late', 'fee', 'improp', 'contact', 'share', 'info', 'bill', 'disput', 'making/receiv', 'send', 'money', 'reward', 'manag', 'lea', 'settlement', 'cost', 'taking/threaten', 'illeg', 'action', 'disclosur', 'verif', 'ident', 'theft', 'fraud', 'embezzl', 'custom', 'relat', 'forbear', 'workout', 'plan', 'closing/cancel', 'use', 'open', 'close', 'compani', \"'s\", 'investig', 'apr', 'interest', 'rate', 'problem', 'unabl', 'pay', 'monitor', 'protect', 'balanc', 'transfer', 'get', 'report/credit', 'score', 'wrong', 'amount', 'charg', 'receiv', 'term', 'chang', 'scam', 'card', 'determin', 'take', 'transact', 'issu', 'caus', 'fund', 'low', 'delinqu', 'avail', 'promis', 'incorrect/miss', 'debit', 'atm', 'sale', 'conveni', 'check', 'bankruptci', 'payoff', 'privaci', 'unsolicit', 'issuanc', 'advertis', 'market', 'shop', 'cash', 'advanc', 'overlimit', \"n't\", 'expect']\n"
     ]
    }
   ],
   "source": [
    "voc = []\n",
    "for w in complaints:\n",
    "    if w not in voc:\n",
    "        voc.append(w)\n",
    "print(voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afa0aeb-7f8c-4a41-890a-cc51be1c8a83",
   "metadata": {},
   "source": [
    "### Einrichten des Wörterbuchs für die Bag-of-Words-Methode, das die Häufigkeit jedes Worts in einer Beschwerde zählt und das BoW-Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f34f7c4-f543-43d9-8f6d-df1f891c6f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      loan  modif  ,  collect  foreclosur  servic  payment  escrow  account  \\\n",
      "0        1      1  2        1           1       0        0       0        0   \n",
      "1        1      0  2        0           0       1        1       1        1   \n",
      "2        0      0  0        0           0       0        0       0        0   \n",
      "3        1      0  0        0           0       0        0       0        0   \n",
      "4        0      0  0        0           0       0        0       0        0   \n",
      "...    ...    ... ..      ...         ...     ...      ...     ...      ...   \n",
      "4195     0      0  0        0           0       0        0       0        0   \n",
      "4196     0      0  0        0           0       0        0       0        0   \n",
      "4197     1      1  2        1           1       0        0       0        0   \n",
      "4198     0      0  0        0           0       0        0       0        0   \n",
      "4199     0      0  0        0           0       0        0       0        0   \n",
      "\n",
      "      incorrect  ...  unsolicit  issuanc  advertis  market  shop  cash  \\\n",
      "0             0  ...          0        0         0       0     0     0   \n",
      "1             0  ...          0        0         0       0     0     0   \n",
      "2             1  ...          0        0         0       0     0     0   \n",
      "3             0  ...          0        0         0       0     0     0   \n",
      "4             0  ...          0        0         0       0     0     0   \n",
      "...         ...  ...        ...      ...       ...     ...   ...   ...   \n",
      "4195          0  ...          0        0         0       0     0     0   \n",
      "4196          0  ...          0        0         0       0     0     0   \n",
      "4197          0  ...          0        0         0       0     0     0   \n",
      "4198          0  ...          0        0         0       0     0     0   \n",
      "4199          0  ...          0        0         0       0     0     0   \n",
      "\n",
      "      advanc  overlimit  n't  expect  \n",
      "0          0          0    0       0  \n",
      "1          0          0    0       0  \n",
      "2          0          0    0       0  \n",
      "3          0          0    0       0  \n",
      "4          0          0    0       0  \n",
      "...      ...        ...  ...     ...  \n",
      "4195       0          0    0       0  \n",
      "4196       0          0    0       0  \n",
      "4197       0          0    0       0  \n",
      "4198       0          0    0       0  \n",
      "4199       0          0    0       0  \n",
      "\n",
      "[4200 rows x 124 columns]\n"
     ]
    }
   ],
   "source": [
    "def CalcBow(voc, complaints):\n",
    "    return {word: complaints.count(word) for word in voc} \n",
    "dataframe_Bow = pd.DataFrame([CalcBow(voc, r) for r in df['issue']])\n",
    "print(dataframe_Bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c5a42b-4723-49bc-b9b9-c53a0f37b5a3",
   "metadata": {},
   "source": [
    "### Erstellung BoW mit der verwendung von sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d57c8c79-8380-49a2-b9e3-514b277819fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   account  action  advanc  advertis  amount  applic  apr  atm  attempt  \\\n",
      "0        0       0       0         0       0       0    0    0        0   \n",
      "1        1       0       0         0       0       0    0    0        0   \n",
      "2        0       0       0         0       0       0    0    0        0   \n",
      "3        0       0       0         0       0       0    0    0        0   \n",
      "4        0       0       0         0       0       0    0    0        0   \n",
      "\n",
      "   avail  ...  transact  transfer  unabl  underwrit  unsolicit  use  verif  \\\n",
      "0      0  ...         0         0      0          0          0    0      0   \n",
      "1      0  ...         0         0      0          0          0    0      0   \n",
      "2      0  ...         0         0      0          0          0    0      0   \n",
      "3      0  ...         0         0      0          0          0    0      0   \n",
      "4      0  ...         0         0      0          0          0    0      0   \n",
      "\n",
      "   withdraw  workout  wrong  \n",
      "0         0        0      0  \n",
      "1         0        0      0  \n",
      "2         0        0      0  \n",
      "3         0        0      0  \n",
      "4         0        0      0  \n",
      "\n",
      "[5 rows x 121 columns]\n"
     ]
    }
   ],
   "source": [
    "vectorizer1 = CountVectorizer()\n",
    "data = vectorizer1.fit_transform(results)\n",
    "data = pd.DataFrame(data.toarray(), columns=vectorizer1.get_feature_names_out())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2647d1b9-cb30-4c46-8672-dc31fe14d1e1",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8fc6799-f23a-4101-8c4d-9d60ec3cf55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    account  action  advanc  advertis  amount  applic  apr  atm  attempt  \\\n",
      "0  0.000000     0.0     0.0       0.0     0.0     0.0  0.0  0.0      0.0   \n",
      "1  0.425306     0.0     0.0       0.0     0.0     0.0  0.0  0.0      0.0   \n",
      "2  0.000000     0.0     0.0       0.0     0.0     0.0  0.0  0.0      0.0   \n",
      "3  0.000000     0.0     0.0       0.0     0.0     0.0  0.0  0.0      0.0   \n",
      "4  0.000000     0.0     0.0       0.0     0.0     0.0  0.0  0.0      0.0   \n",
      "\n",
      "   avail  ...  transact  transfer  unabl  underwrit  unsolicit  use  verif  \\\n",
      "0    0.0  ...       0.0       0.0    0.0        0.0        0.0  0.0    0.0   \n",
      "1    0.0  ...       0.0       0.0    0.0        0.0        0.0  0.0    0.0   \n",
      "2    0.0  ...       0.0       0.0    0.0        0.0        0.0  0.0    0.0   \n",
      "3    0.0  ...       0.0       0.0    0.0        0.0        0.0  0.0    0.0   \n",
      "4    0.0  ...       0.0       0.0    0.0        0.0        0.0  0.0    0.0   \n",
      "\n",
      "   withdraw  workout  wrong  \n",
      "0       0.0      0.0    0.0  \n",
      "1       0.0      0.0    0.0  \n",
      "2       0.0      0.0    0.0  \n",
      "3       0.0      0.0    0.0  \n",
      "4       0.0      0.0    0.0  \n",
      "\n",
      "[5 rows x 121 columns]\n"
     ]
    }
   ],
   "source": [
    "vectorizer2 = TfidfVectorizer(min_df=1)\n",
    "mod = vectorizer2.fit_transform(results)\n",
    "data_IDF = pd.DataFrame(mod.toarray(), columns=vectorizer2.get_feature_names_out())\n",
    "print(data_IDF.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e012b4-4965-4933-b424-47ae043d85ad",
   "metadata": {},
   "source": [
    "# Semantische Analyse\n",
    "### LDA - Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1c1490a-559b-4e85-b6a5-afe530ee4682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: \n",
      "Topic:  0 :  2.857142875724331 %\n",
      "Topic:  1 :  2.8598540844835294 %\n",
      "Topic:  2 :  2.8571429007493934 %\n",
      "Topic:  3 :  2.8582703805523084 %\n",
      "Topic:  4 :  2.857142909067227 %\n",
      "Topic:  5 :  2.8595130062591916 %\n",
      "Topic:  6 :  82.85093384316401 %\n"
     ]
    }
   ],
   "source": [
    "lda_mod1 = LatentDirichletAllocation(n_components=7, learning_method='online', random_state=42)\n",
    "lda = lda_mod1.fit_transform(data)\n",
    "print(\"Topic: \")\n",
    "for i, topic in enumerate(lda[0]):\n",
    "    print(\"Topic: \",i,\": \",topic*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80a83f3-7174-4601-9f7e-8a749fe066f7",
   "metadata": {},
   "source": [
    "### Die Schlüsselwörter für jedes Thema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06a21dfb-16ce-4f69-b546-e219ddde29ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "credit incorrect inform report communic tactic bill disput protect money\n",
      "\n",
      "Topic 1:\n",
      "debt collect attempt cont owe applic broker mortgag origin line\n",
      "\n",
      "Topic 2:\n",
      "credit report investig compani get unabl score fee account late\n",
      "\n",
      "Topic 3:\n",
      "manag account close open loan repay info improp contact share\n",
      "\n",
      "Topic 4:\n",
      "problem low fund caus pay unabl card credit decis underwrit\n",
      "\n",
      "Topic 5:\n",
      "servic account loan payment escrow disclosur verif debt statement process\n",
      "\n",
      "Topic 6:\n",
      "loan foreclosur modif collect withdraw deposit lea action threaten illeg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voca1 = vectorizer1.get_feature_names_out()\n",
    "num_topics = 7\n",
    "\n",
    "for i in range(num_topics):\n",
    "    comp = lda_mod1.components_[i]\n",
    "    sd_words = sorted(zip(voca1, comp), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    print(f\"Topic {i}:\")\n",
    "    print(' '.join(word for word, _ in sd_words))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca093a2b-752e-4e0f-bbed-2f1698d01b3b",
   "metadata": {},
   "source": [
    "### LSA - Latente semantische Analyse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c531e2c-ae05-47ae-b97b-2c89d1cbb358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: \n",
      "Topic:  0 :  97.85178975575124 %\n",
      "Topic:  1 :  -17.618934235813434 %\n",
      "Topic:  2 :  -0.016028419919769638 %\n",
      "Topic:  3 :  -10.302836566059026 %\n",
      "Topic:  4 :  1.2096440185370292 %\n",
      "Topic:  5 :  -8.697545631096092e-07 %\n",
      "Topic:  6 :  8.005335195532323e-07 %\n"
     ]
    }
   ],
   "source": [
    "lsa_mod2 = TruncatedSVD(n_components=7, algorithm='randomized', n_iter=10)\n",
    "lsa = lsa_mod2.fit_transform(mod)\n",
    "print(\"Topic: \")\n",
    "for i, topic in enumerate(lsa[0]):\n",
    "    print(\"Topic: \",i,\": \",topic*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37ac766-2ee1-4346-9955-53a6ad4d4c3a",
   "metadata": {},
   "source": [
    "### Die Schlüsselwörter für jedes Thema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bf4baa9-3bcb-49ad-9586-eca5c3fa0b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "foreclosur modif collect loan escrow servic payment account attempt cont\n",
      "\n",
      "Topic 1:\n",
      "escrow servic payment account loan manag close open repay lea\n",
      "\n",
      "Topic 2:\n",
      "report credit inform incorrect compani investig score get unabl use\n",
      "\n",
      "Topic 3:\n",
      "debt attempt cont owe collect verif disclosur account escrow servic\n",
      "\n",
      "Topic 4:\n",
      "manag close open account lea foreclosur modif collect line delinqu\n",
      "\n",
      "Topic 5:\n",
      "communic tactic lea manag loan take unabl pay shop get\n",
      "\n",
      "Topic 6:\n",
      "deposit withdraw unabl pay illeg taking threaten action repay get\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voca2 = vectorizer2.get_feature_names_out()\n",
    "num_topics = 7\n",
    "\n",
    "for i in range(num_topics):\n",
    "    comp = lsa_mod2.components_[i]\n",
    "    sd_words = sorted(zip(voca2, comp), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    print(f\"Topic {i}:\")\n",
    "    print(' '.join(word for word, _ in sd_words))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bee1b1-6df8-4c48-83ba-29557ae41397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c54576f-2523-4dad-9178-0343f310c488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
